#### 数据结构

##### LSM树

B+树提供了高效的范围扫描的功能，得意于其叶子阶段之间是相互连接的。并且按照主键是有序的。在一颗B+树中用户可以得到页表级别的位置信息。

LSM树是另一种数据组织方式,输入数据存储在日志文件中,这些文件完全有序.当日志文件被修改的时候,对应的更新会被保存在内存中,用于加速查询.

当系统经过多次更新之后,内存空间被填满,LSM树会把有序的记录写到磁盘中.同时创建一个新的数据存储文件.

存储文件与B树类似,不同的是对其顺序做出了优化,所有节点都是满的,且按照页存储.修改数据文件操作通过滚动合并完成.

多次刷写之后,后台的小文件会被合并成大的文件,这样磁盘上的查找就会限定在几个大文件中了.查询的时候优先在内存中查找,其次进行磁盘查找.

删除是一种特殊的更改,当删除标记存储之后,查找会跳过删除的键.当页被重写的时候,有删除的标记会被丢弃.

LSM树具有较高的磁盘传输效率,并能够处理大量的数据.使用日志文件和内存存储将随机写转换为顺序写.

#### 存储格式

##### 写过程

1. 决定数据是否需要写入到HLog中(实现为WAL,可以在服务器失败的时候回滚没有持久化的数据)
2. 一旦写入到WAL,数据就会存储到MemStore中,如果MemStore满了,则会刷写到磁盘上(会在HDFS上形成一个新的HFile)

##### 文件系统结构

通常情况下,文件系统结构的形式如下

```markdown
/<hbase-root-dir>/<tablename>/<encoded-regionname>/<column-family>/<filename>
```

一个region超过配置中region大小的最大值的时候,region就需要进行拆分,会创建一个`split`目录.用来临时存放两个子region相关的数据.如果拆分过程成功,之后会被移动到表目录中.并形成两个新的region,每个region是原来的一半.同时原来的region会下线,不会接受客户端的请求.

从目录上来看,如果没有`.tmp`目录,则表示没有进行过压缩.如果没有出现`recovered.edits`目录,则表示没有WAL出现过重做.

##### 压缩合并

压缩合并主要分为两种,分别是**minor合并**以及**major合并**.

minor合并默认情况下最大文件数量为10,可以通过`hbase.hstore.compaction.max`配置.任何比最大合并大小大的文件都会被排除在外.

major合并是将所有文件压缩成一个文件.由于需要花费很多时间,所以需要定时的进行合并.

##### HFile文件格式

<img src="E:\截图文件\HFile文件格式.png" style="zoom:67%;" />

文件长度是可变的,固定的部分是`File Info`和`Trailer`部分.`Trailer`中有指向其他块的指针.它是在数据持久化结束的时候写入的,写入之后称为不可变的数据存储文件.

HFile的文件主要分为三个主要的部分,一部分是KeyValue的真实数据部分,一个部分是HFile的Header部分和Trailer信息.还有一部分是文件信息FileInfo部分.

##### KeyValue格式

<img src="E:\截图文件\KeyValue结构.png" style="zoom:67%;" />



这里有`KeyLength`和`ValueLength`两个参数，用于指示key和value的数量，这样可以忽略键值进行跳跃访问。另一方面，压缩由于着眼于有限的数据窗口，并且其中重复的数据都能够被有效的压缩。存储文件中所有的KeyValue都被有效地存储，有助于将类似的键存放在一起。

#### 预写日志(WAL)

由于存储在内存中是不稳定的，所以引入了WAL的概念。

HBase中实现WAL的类是`HLog`,当HRegion实例化的时候，HLog实例会被当做一个参数传入到HRegion的构造器中。当一个Region接收到一个更新操作的时候，可以将数据保存到一个共享的WAL实例中。

##### 日志滚动

日志写入的大小是由限制的,`LogRoller`作为一个后台线程运行，并且在特定的时间间隔内滚动日志。参数可以设置`hbase.regionserver.logroll.period`,默认为60min。

表示每60min旧的文件会被关闭，然后开启新的日志文件。经过一段时间，系统会积攒一系列数量不断增加的日志文件。HBase会调用`HLog.rollWriter`滚动当前日志文件。接着调用`HLog.cleanOldLogs`清空旧日志，这个方法会检查存储文件中的最大序列号。如果所有序列号都小于存储的序列号，则将文件移动到`.oldlogs`文件夹下。

##### 回放

master和region服务器需要配合起来精确地处理日志文件，特别是从服务器失败中恢复的时候，WAL用来保证数据更新安全。

1. **单日志**

单日子设计存在的一个问题就是所有的数据更改都混在一个日志文件中，并且没有任何索引。

2. **日志拆分**

日志文件在两种情况下会回放，即**集群启动**以及**服务失效**的时候。master启动的时候，会检查文件系统中HBase目录下是不是含有`.logs`日志文件，以及日志有没有分配region服务器。

在日志的数据改动被回放之前，日志需要单独的放在每个region对应的单独日志文件中。这个过程叫做**日志拆分**。Zk将没有被丢失的日志文件分发给一个region服务器。通过监测Zk发现需要执行的工作，一旦master指出某一个日志可以被处理，那么它们会竞争这个任务，获胜的region会在一个线程中读取并拆分这个日志文件。

##### 数据恢复

集群启动的时候，region都会被打开，此时region会检查recovered.edits目录是否存在。如果该目录存在就会打开目录中的文件，并开始读取文件所包含的数据更改的更改记录。region会按照序列ID的顺序来恢复数据。

一旦recovered.edits文件夹中的文件被处理完毕之后，且其中数据更改也被写入到磁盘之后，该文件夹就会被删除。

#### Region

HBase对于Region的检索提供两类特殊的表.即`-ROOT-`和`.META`其中`-ROOT-`中存放有`.META`表中region的位置.`.META`对应于用户表中的位置.HBase设计中只有一个root级别的region.

##### 生命周期

| 状态名称      | 描述                           |
| ------------- | ------------------------------ |
| Offline       | Region下线                     |
| Pending Open  | 打开region的请求发送给服务器   |
| Open          | 服务器已经打开region           |
| Pending Close | 关闭region请求被发送到服务器上 |
| Closing       | 服务器正在关闭region           |
| Closed        | region已经被关闭了             |
| Splitting     | 服务器已经开始切分region       |
| Split         | region已经切分                 |

#### 复制与容灾

HBase复制中最基本的架构是**主推送**,因为每个region服务器都有自己的WAL.所以很容易保存现在正在复制的位置,

复制时异步进行的,这就意味着集群可以是地理上彼此远离的.他们的连接可以在某些时间断开.在主集群上的修改不能马上在集群上进行同步.参与复制的集群的规模可能不对等.主集群会通过随机分配尽量均衡集群的负载.

##### 内部机制

1. 挑选需要复制的目标服务器

   当主集群region服务器初始化复制源到从集群的时候,

2. 跟踪日志中被复制到的位置

   每个主集群region服务器在znode目录中都有器znode节点.并且每个从集群都有对应的znode.并且每个znode都包含一个需要处理的HLog队列.

3. 读取,过滤以及发送数据修改

   一个源尝试读取日志文件,并尽可能将它们传送到从集群的接受服务器上.由于日志过滤的限制,只有GLOBAL类的且不属于目录表日志项的KeyValue会被保留.第二个限制是集群同步总大小,默认64M.

   一旦读取的缓冲区超过最大值.或者读取到了日志文件的末尾.源线程会停止读取并随机挑选一个可以接受数据的从服务器来接受数据.会把RPC请求直接发送到挑选的服务器上.如果读取完毕,则会在zk中删除相应的znode节点.否则,会移动一个偏移量,并注册进去.

4. 清理日志

   如果没有启动同步复制,master日志清理线程会按照配置的生产器TTL删除旧的日志.