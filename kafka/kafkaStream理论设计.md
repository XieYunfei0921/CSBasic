#### Kafka Stream概念

kafka Stream的优势

+ 简单轻量级的客户端库，可以嵌入到java应用中并与其他存在的包进行整合，部署。
+ 除了Kafka之外，无需依赖其他类型的外部依赖。
+ 支持对本地状态的容错，可以快速高效的开启状态操作。例如窗口join和聚合。
+ 支持仅仅一次消费的语义，保证消息有且会被消费一次
+ 使用实时记录处理，以获取毫秒级的处理延时，支持基于窗口操作的事件时间
+ 支持高级消费者和低级消费者

##### 流式处理拓扑关系

+ 流式处理是kafka stream的基本抽象，代表无界的，连续的更新数据集。一个流式可排序的，可以进行重演的，以及具有容错功能的可变数据记录序列，这个数据记录是kv型数据对。
+ 流式处理应用是一个可以利用kafka stream库的程序。通过处理逻辑拓扑图定义了计算逻辑，这个拓扑图的阶段是流式处理器，而边指定就是连接的流。

- 流式处理器是拓扑图中的一个节点，代表流式数据转换的处理步骤，从上游读取输入记录，使用在处理器上的操作，产生一个或者多个输出记录到下游处理器中

有两种特别的处理其

+ Source处理器： 特殊类型的处理器，没有上游节点，从一个或者多个kafka topic中获取输入记录，并发送数据到下游处理器中
+ Sink处理器：没有下游节点的处理器，发送接收的数据到指定的kafka topic中

注意到正常的处理器节点在处理当前记录的时候是可以被获取的。因此处理结果可以就是传输到Kafka中或者写出到外部系统中。

<img src="E:\截图文件\Kafka流式拓扑图.png" style="zoom:67%;" />

kafka stream提供两种定义拓扑逻辑图的方式。

+ Kafka Stream DSL: 通用转换操作，例如`map`,`filter`,`join`和`aggregation`

低级处理器API允许开发者定义和连接自定义的处理器以及和状态存储器交互.

##### 计时器

流式处理重要的处理就是对计时器的处理,且需要对其进行模型化和整合.例如,窗口操作就是基于计时器的.

流式处理中计时器的语义包括:

+ **事件时间** 

  事件或者数据记录发生的时间点

+ **处理时间**

  事件/记录被流式应用处理的时间点

+ **消化时间**

  事件/数据记录存储到topic的时间.与事件时间不同的是当记录添加到broker的topic时会产生时间戳信息

事件时间和消化时间的选取取决于kafka的配置.在kafka 0.10.x以上版本,时间戳自动添加到kafka消息中.通过接口`TimestampExtractor` 将时间戳分配到每个数据的记录上,每个记录的时间戳描述了带有时间信息的记录,因此可以进行时间相关的操作.例如窗口操作.因此,当新纪录到达处理器的时候会进行处理.称作这个数据驱动的时间为应用的**流式时间**.`TimestampExtractor` 是一种离散实现,提供不同类型的流式时间定义语义.例如,检索基于实际数据记录内容的时间戳信息.开发者也可以定义不同种类的语义.

最后,无论kafka stream何时写入记录,都会指定时间戳信息.时间戳根据上下文指定:

+ 当新的输出记录通过产生输入记录产生的时候,例如,`context.forward()`会触发`process()`函数调用,输出记录时间戳继承于输入时间戳.
+ 当输出记录通过周期性函数产生的时候,例如``Punctuator#punctuate()`,输出记录时间戳定义为当前内部时间。
+ 为了聚合方便，结果的时间戳更新记录会变成所有输入记录中最大的时间戳。

##### 聚合

聚合操作花费一个输入流或者是表，通过合并多个输入记录成为一个输出记录可以让出一个新的表。在Kafka Steam 的DSL中，聚合操作的输入流可以是KStream或者是KTable，但是输出流总是KTable。允许kafka Stream再value生成和提交之后对其进行聚合。当这样的乱序结果到达的时候，聚合的KStream或者KTable会提交一个新的聚合值。因为输出是一个KTable，新的值必须使用相同的key值重写旧的值。

##### 窗口

窗口操作允许你控制相同key的记录组合，用于带状态的操作，例如`aggregations` 和`joins`操作.窗口按照每个key进行定位.

窗口操作在Kafka Stream的DSL中可用,当使用窗口的时候,可用指定窗口的周期.这个周期控制了给定窗口乱序数据记录的等待时间.如果记录在窗口之后才到达,记录就会被抛弃,且不会再这个窗口中处理..特别地,当一个记录的时间戳信息属于这个窗口但是当前stream流时间大于窗口结束时间与这个周期的和的时候,依旧会被抛弃.

乱序记录需要在应用中进行合适的处理.主要依赖于时间语义的处理,可以对乱序数据记录进行处理.在处理的时候,语义就是**当记录被处理的时候**,意味着乱序记录的语义不是可适用的,按照定义没有记录可以是乱序的.乱序记录只能被认作事件时间,这种情况下,kafka stream就可以处理乱序记录.

##### 状态

一些流式处理应用不需要状态,意味着消息的处理和其他消息的处理是独立的.但是,可以连接输入流或者对数据记录进行分组聚合的操作,这些操作可以有Kafka Stream DSL提供.

kafka stream提供了状态存储,可以流式应用存储和查询状态.这个是实现状态操作的重要功能,每个kafka stream中的任务嵌入了一个或者多个这样的状态存储.可以通过API对其进行处理.这个状态存储器既可以是持久化的kv存储,也可以是内存的hashMap或者其他高效的数据结构.kafka stream提供容错和原子性的状态恢复.

kafka stream允许直接的状态只读查询.通过交互式查询实现.

##### 处理保证

流式处理中最重要的就是保住消息是否仅仅被消费一次的语义.

在Kafka 0.11.0.0版本之前,kafka仅仅支持至少消费一次的传输语义.自从kafka 0.11.0.0开始,kafka添加对生产者发送消息到不同topic下的支持,使用的是事务式发送方式，kafka stream通过平衡这些功能实现了仅仅一次消费的语义。且保证不仅会仅仅一次发送到输出topic中，同时也会存储到状态存储中。

注意到kafka stream与其他流式处理不同的是端对端的仅仅一次消费语义的保证。框架保证了kafka stream与底层kafka存储系统紧紧相连，且保证会在输入topic上提交，且会更新状态存储，并且写入到输出topic的过程是原子性的。

###### 乱序处理

处理保证每个消息仅仅被消费一次之外，流式处理另一个保证的就是去处理乱序数据，乱序数据会影响基本的逻辑。有两种原因可能导致乱序数据

+ 分区内，记录的时间戳不随着偏移量的增加而增加，因为kafka stream尝试在分区内部处理实例，且会按照偏移量的顺序进行。可能导致大的时间戳（具有小的偏移量）先处理的情况。
+ 在stream task中，可能正在处理多个topic分区，如果用于配置应用不去等待所有分区囊括所有的缓冲数据且使用最小时间戳从分区中取数据处理，之后在其他分区中获取了更新的时间戳，这样就导致了乱序。

对于没有状态的操作，乱序数据不会影响处理逻辑。对于有状态的操作，例如聚合以及join操作，但是乱序数据可能导致处理逻辑错误。如果用户希望去处理这些乱序数据的话，需要应用等待更长的时间。使用延迟去交换正确性。在kafka stream中，用户可以配置窗口操作，用于窗口聚合，以达到这样的交易效果。至于join的操作，不许意识到溢写乱序数据还不能通过延时进行处理：

+ 对于stream-stream join，处理乱序逻辑正确，但是会导致结果包含不需要的null值。
+ 对于stream-table join，不能处理乱序数据，会产生不可预测的结果
+ 对于table-table join，不能处理乱序数据，但是join的结果是一个可变的日志流，且最终会保持一致性。

#### Kafka Stream架构

通过构建kafka生产者和消费者库可以简化应用的开发，且平衡本地kafka的功能以提高数据的并发，分布式协调，容错等功能。下图显示了kafka stream的架构图。

<img src="E:\截图文件\kafkaStream.png" style="zoom:67%;" />

##### Stream分区和任务

kafka分区的消息层用于存储和传输数据，kafka stream 分区中用于产生数据。两种情况下分区都具有数据本地化，可扩展性，高性能以及容错性的特性。kafka使用分区和任务的改变作为并行模型的逻辑单元。在kafka和kafka stream有这相似的连续。

+ 每个流式分区都是全局有序的数据记录序列
+ 数据记录映射到kafka topic中的消息
+ 数据记录的key决定了kafka和kafka stream的分区情况。例如，数据是怎么在topic之间路由的。

通过将处理逻辑图拆分可以获取多个任务。精确的说，kafka stream创建了一个指定数量的任务，每个任务从输入流中分配了一个分区列表。任务分区分配不会改变，这样每个任务都有指定的并行度，可以基于分配的分区实体化处理器。

简单来说，最大并行度取决于stream 任务的最大数量，有熟人topic的分区最大数量决定。例如，输入topic有5个分区，可以运行5个以上的实例。这些实例可以处理这个topic的数据。如果需要运行更大数量的应用数量，可能有的线程会保持空载运行。但是如果一个实例宕机，空载实例就会暂停之前的工作。

下图显示了两个任务，每个都指派了一个输入流

<img src="E:\截图文件\任务分配.png" style="zoom:67%;" />

##### 线程模型

kafka stream允许用户配置线程数量，库可以使用这些线程并发处理任务。线程可以执行一个或者多个任务。例如下图所示的，一个线程运行链各个流式任务。

<img src="E:\截图文件\流式线程.png" style="zoom:80%;" />

这个使得并行运行流式拓扑图很方便。topic的分配可以有kafka stream的调整功能进行处理。可以启动与kafka topic相同的线程数量，通过运行任务的实例，每个线程由至少一个输入分区去处理。

##### 本地状态存储

kafka stream 提供了状态存储器，流式处理可以使用这个来对应用数据进行存储和查询，这个是状态操作的重要功能。kafka stream的DSL会自动创建并且管理这样的状态存储器，例如调用`join()`,`aggregate()`以及窗口操作的时候.

kafka流式应用的每个流式任务都会集成一个或者多个本地状态存储器.可以通过API进行存储和查询.kafka stream提供了容错和自动回复功能.

下图显示了带有本地状态存储的流式处理过程

<img src="E:\截图文件\状态存储.png" style="zoom:67%;" />

