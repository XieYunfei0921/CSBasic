#### 持久化

kafka依赖于文件系统去存储和缓存消息.但是通识上来说磁盘读写缓慢的.为了弥补性能上的差异,现代OS在主存中进行磁盘缓存(**高速缓存**).现代OS会分配空闲内存空间给磁盘缓存.所有磁盘的读写都会通过主存进行.这个功能不能直接由关闭IO完成,所以尽管处理过程维护了处理中的数据缓存,这些数据会在OS的页缓存中备份,可以高效地存储两次.

进一步,来说,可以在JVM的基础上进行构建,使用java内存是需要注意到两点

1. 对象存储在内存中开销非常大,经常是数据存储的两倍
2. 随着堆内数据的增加,GC变得更加的缓慢

因此,需要同时使用文件系统和依赖页缓存.如果服务重启缓存保持运行.

消息系统中使用的持久化的数据结构,经常每个消费都会使用一个B树或者生成其他随机数去维护消息的元数据.B树是最通用的数据结构,可以获取消息系统中大量的事务/非事务语义.查找的时间复杂度为O(log N).正常情况下基本上等于是个常数时间,但是对于磁盘操作来说并不是这样.磁盘查找需要10ms,且每个磁盘同一时刻只允许一次查找,所以并行度被限制.假定磁盘查找需要大量的开销.因此存储系统混合了高速缓存和慢速的磁盘查找.

持久化的队列可以被简单的读取并添加到文件中.这个数据结构认为所有的操作都是O(1)的时间复杂度,且读取不会阻塞写出和其他操作.尽管如此,查找的性能仍然很大,这样在大量的读写情况下,使用1/3的代价和3倍的容量.

为了获取虚拟磁盘空间,提供一些消息系统中不常使用的功能.例如,kafka中数据不是消费完毕就会删除的,而是需要保持一定的周期,这个会对消费者提供很大的处理灵活性.

#### 高效

主要通过处理web的激活的数据,这个数据的量比较大,每个分页都会产生大量的写出操作,此外,假定每条消息都被至少一个消费者.

注意影响系统效率的主要行为许多小的IO操作,以及过多的字节拷贝工作.

小IO问题发生在客户端和服务器之间且用于服务器自己的持久化操作.为了避免这种情况，协议中围绕着**消息集合**进行抽象。

这个会自然的将消息聚合在一起，允许网络将组消息聚合在一起且分担网络开销，而不是同一个时间仅仅发送一条消息。在服务器运行的时候，服务器会轮流地添加消息块到日志中，消费者会获取一个数据块的消息。

这个简单的优化会加速生成的幅度。批量获取会生成更大的网络数据包以及较大的磁盘操作以及连续的数据块。kafka可以将其转换为随机的消息写入到消费者的工作流中。

另一个低效的操作就是字节拷贝了，关键的问题是加载数据的时候影响较大。为了避免这种情况下，使用标准的二进制消息格式，这个可以被生产者，broker，消费者共享。因此数据块的传输可以不修改的进行。由broker维护的消息日志仅仅是一个文件目录，消息集序列会被写入到磁盘中，生产者和消费者的消息形式相同。

理解发送文件的影响，重点是理解通用数据意义：

1. 操作系统读取磁盘数据到内核的页缓存中
2. 应用从内核空间读取数据到用户缓冲区中
3. 应用将数据写回内核中
4. 操作系统复制socker缓冲区的数据到一个NIC缓冲区中，这里可以通过网络发送数据

这个是低效的，有4次拷贝以及两个系统调用。使用发送文件的方式，通过使用OS发送页缓存的数据到网络中，重新拷贝被避免了。所以在这个优化路径中，仅仅最后需要拷贝到NIC缓冲区中。

希望对多个消费者进行通用的操作。使用**零拷贝**的优化技术，数据仅仅会拷贝到页缓存中一次，且在每次消费的时候会重新使用（而不是存储在内存中，每次需要拷贝到用户空间中）。这个允许消息按照一定的比率进行消费。

页缓存和发送文件的联合使用意味着kafka集群中可以在磁盘上没有读取的操作，因为可以通过缓存的范式进行数据服务。

#### 端对端的批次压缩

在一些情况下，性能瓶颈不是CPU或者磁盘而是网络的带宽。这个对于pipeline来说，需要通过广域网的数据中心发生数据。当然，用于可以将消息压缩，但是压缩比率可能很低。高效的压缩需要压缩多个消息而不是单条的进行压缩。kafka支持高效的批格式处理，一批消息可以一起压缩且按照这个格式发送到服务器。批次的消息会被写入，且在日志中保留着压缩的形式，且只有消费者可以对其进行解压缩。

kafka支持Gzip，Snappy，lz4，zStandard压缩协议。

#### 生产者

##### 负载均衡

生产者直接将消息发送到broker中，这个broker是分区的leader，且没有任何的中间路由层。为了帮助生产者进行这个操作，kafka节点可以回应元数据关于服务器存活状态以及leader的位置信息的请求。客户端控制发布消息的分区信息，这个可以随机处理，由随机的负载均衡处理，可以被分区函数的语义处理。这里保留分区语义的接口，允许用于指定分区的key，且使用hash进行分区。这个可以允许消费者去进行消费的位置假设。分区的方式可以显示地允许消费者的位置感知处理。

##### 异步发送

批量处理具有高效的特性，为了开启kafka的批量处理，生产者需要在内存中累加数据，且需要在单次请求中发送大批量数据。这个批次可以设置为指定数量的消息，或者是等待指定时间范围的消息(例如 64K或者 10ms)。这样会降低服务器的IO操作次数，配置缓存且获取更高的吞吐量。

#### 消费者

##### 推送和拉取数据的比较

首先需要考虑的就是消费者是否需要从broker拉取数据，还是broker将数据推送给消费者。kafka使用了传统的处理方案，这个方案使用了共享的消息系统，数据从生产者推送到broker，且由消费者从broker中拉取。

一些以日志为中心的系统，例如Scribe和Flume，数据推送的方式是推送式的。但是基于推送式的系统处理不同消费者的时候就有问题。这里对于大多数消费者可以消费者最大的比率，在推送式系统中意味着消费者会被压垮（消费比率不足的时候）。

基于拉取的另一个优势就是可以将批量数据发送给消费者。基于推送的系统必须要选择是立即发送请求还是累积更多的数据再发送。基于拉取的系统的消费者总是在当前日志指针之后拉取可用的消息，所以消费者可以没有延时的获取批量

##### 消费者位置指针

消费者的位置指针指示了消费的位置，这个是消息系统的关键性能。大多数消息系统保持broker中消费的元数据。随着消息被消费者消费，broker会记录事实位置或者等待消费者的确认。由于大多说消息系统的存储数据结构扩容能力很长，因此当broker知道消息被消费之后消息会被立即删除，保持数据量的大小。

如果broekr每次处理消费的记录的时候记录消息，如果消费者处理消息失败那么消息就会丢失。为了解决这个问题，许多消息系统设置了将消息标志为发送但为消费的标记。这样broker就会等待消费者确认消费的状态。这个策略修正了消息丢失的问题，但是会引入新的问题。首先，如果消费者处理消息，但是在发送确认信息前失败了，那么消息就会被消费两次。关于这个问题，现在broker必须保证每条信息的多个状态参数(首次使用的时候会加锁,这样就不能第二次使用,然后将其进行临时标记,以便可以可以移除).

kafka进行了不同的处理,topic被划分成有序的分区,每个分区被每个消费者组的指定的消费者消费.这就意味着每个分区的消费者位置是一个整数,是下一条消费消息的偏移量.这个使得消费状态非常简单,就是分区的一个数字.这个状态可以周期性设置检查点.消费者可以倒回到旧的偏移量并重新消费数据.

##### 离线数据负载

可扩展的持久化引擎允许消费者周期性的消费离线系统数据(例如Hadoop或者是相关数据仓库的数据)在hadoop的情况下,通过在map任务分割负载对其进行并行化处理,hadoop系统使用任务管理器,任务失败则会进行安全的重启.

##### 静态关系

静态关系用于提升流式应用的可用性,消费者组合其他应用按照组的平衡协议的基础上.重平衡协议依赖于组协调者去分配实例的id给组员.产生的id是临时的,且在重启或者重新加入的时候会改变.对于基于应用的消费者来说,动态关系可能引起较大规模的任务重分配.对于较大的状态应用中,shuffle任务需要长时间去恢复本地状态.kafka组管理协议允许组成员提供持久化的实例id.基于这些id信息,组关系可以保持不变

如果希望使用静态关系:

- broker和客户端都要升级到2.3版本以上
- 设置`ConsumerConfig#GROUP_INSTANCE_ID_CONFIG`对于每个消费者实例是组内唯一标识的.
- 对于kafka流式应用,对于kafka流式对象使用`ConsumerConfig#GROUP_INSTANCE_ID_CONFIG` 作为唯一标识.

#### 消息传输语义

既然理解了生产者和消费者的工作方式，下面来讨论讨论kafka保证生产者和消费者的语义。下面有多种可能的消息保证方式。

+ **至多一次**：消息可能会丢失但是不会重新发送
+ **至少一次**：消息不会丢失但是可能会重发
+ **仅仅一次**：消息有且会被发送一次

需要将其划分为两个问题，即发布消息的持续时间和消费消息的持续时间保证。

许多系统提供**仅仅一次**(exactly once)的发送语义,但是读取输入是很重要的.大多数都会产生误解.Kafka语义时直接的,发布消息的时候,消息会被提交到日志中.一旦发布的消息被提交,只要broker副本分区仍然处于存活状态,消息就不会被丢失.

一个工作正常的broker尝试保证生产者和消费者,如果生产者希望发布消息以及处理可能发生的网络错误.这个相似于使用自动生成的key插入数据库中类似.

在Kafka 0.11.0.0之前的版本,如果生产者不能接收到消息提交的信息,有选择的可能性且需要重新发送消息.这里提供了至少一次的发送语义(因为即便是发送成功,消息仍然可能会被再次写入到日志中).

自从kafka 0.11.0.0版本开始,kafka生产者支持幂等性的发送,这个保证了重新发送不会导致日志中的重复条目消息.为了达到这个功能,broker使用序列化编号分配生产者的id的消息.这个编号由生产者在每条消息中发送.此外,生产者支持发送消息到多个topic分区中的能力,这里主要实现了事务相关的语义:所有的消息要不全部写入,要不全部不写入.这个的主要使用情景就是**仅仅一次**的处理方式.

不是所有的应用情景都需要强保证的,对于延迟比较敏感的应用,允许生产者指定需要的持续时间信息.如果生产者指定了的消息提交的等待时间,但是生产者可以指定需要异步发送还是需要等待到leader持有消息为止.

下面描述消费者视角下的语义,所有副本都有相同,偏移量相同的日志.消费者控制日志中的位置指针.如果消费者从来没有宕机,可以仅仅存储位置指针到内存中,但是如果消费者是啊比且需要其他进程处理这个分区.下面有关于处理消息及更新位置指针的多个配置:

1. 可以读取消息,然后在日志中保持位置指针,最后处理消息.这种情况下,但是在保存消息处理的输出之前,保存位置指针之后,消费者可能会宕机.这种情况下,进程会起始于保存的位置指针出,但是先与指针的部分消息未被处理.这个对应于**至多消费一次**的语义.
2. 可以读取消息,处理消息,最后保存位置指针,.在处理消息之后保存位置指针之前会宕机.就会出现**至少消费一次**的语义.在大多数情况下,消息有一个主键,这样可以进行幂等性的更新.

那么仅仅消费一次是如何保证的呢?当从一个kafka topic的消费且生产到另外一个topic的时候,在kafka 0.11.0.0版本开始可以通过处理事务的方式进行包装.消费者位置指针以消息的形式存储到topic中,所以可以在相同的事务中将偏移量写入到kafka中.如果事务抛弃了的话,消费者指针会回复到旧值，且输出topic产生的数据对于消费者不可见，主要是依靠于隔离等级来实现。

默认情况下是**读但是不提交**，所有消息对于消费者来说都是可见的，尽管是抛弃事务的部分内容。但是在**读且提交**的模式下，消费者会返回来自事务中已经提交的消息。

当写出到外部系统的时候，主要限制是协调消费者的位置指针。典型的实现方式就是在消费者位置指针和消费者输出存储间使用双向提交。但是可以进行更简单的处理，即消费者存储位置指针到与输出相同的位置处。对于大多数消费者希望写入的输出系统可能不支持双向提交。考虑到使用kafka 连接器处理这种情况。

在kafka Stream中kafka支持高效的exactly-once传输方式，且事务的生产者和消费者可以保证仅仅消费一次的传输。目标系统的仅仅一次消费需要系统之间进行协调，但是kafka提供了偏移量。此外，kafka默认保证至少一次传输，允许用户实现至多一次传输(关闭依赖生产者和消费者提交偏移量优先于处理批次消息的功能).

#### 副本

通过可配置的服务器数量,kafka对每个topic分区进行备份.在集群中的某个服务器失败的时候,允许原子性的故障转移到这些副本上.所以消息仍旧可以保持可以的状态.

消息系统提供了副本相关的功能,但是在配置中,这个不是重度使用的.服务是非激活的,吞吐量受到很大的影响.需要高精度的手动操作.此外,kafka默认情况下使用副本.副本单元就是topic的分区.在没有失败的情况下,kafka的每个分区都含有一个leader且包含0-N个follower.副本总是包含leader以及相关的副本因子.所有读取和写出都会在leader的分区进行处理,典型地,分区数量超过broker的数量且leader在broker中呈分散分布.follower的日志保持与leader的日志一致.即包含相同的偏移量和按照同样顺序的消息.

follower从leader中消费消息,方式如图正常的kafka消费者一致.follower从leader拉取,lesder需要配置参数,进而允许follower自动批次获取日志.

在多数分布式系统中,自动处理失败需要对存活节点进行预先定义,对于kafka来说,节点存活需要下述两个条件:

1. 节点必须维持与zk的联系(通过zk的心跳机制)
2. 如果是follower必须跟随leader

leader保持对同步节点的追踪,如果follower死亡,卡死,或者长时间未更新,leader会从同步副本列表中移除这个follower.卡死的条件可以通过配置`replica.lag.time.max.ms `进行配置。

分布式系统中，在失败模型中需要处理失败/恢复的行为.

当分区的所有同步副本都已经放入日志中可以对消息提交进行更精确的定义.只有提交的消息才会给消费者这,意味着消费者不需要担心leader失败情况下消息是否会丢失.生产者可以配置是否等待消息的提交,.考虑到延时和持续时间.这个偏好有ack配置控制.

注意到当生产者申请消息写入到副本中的消息时,topic配置了同步副本的最小值,如果消息被生产者缺,那么消息可以被提交,消费.只要有一个副本存活,kafka保证了提交的消息不会丢失.kafka会在节点短时间失败的情况下保持可用,但是网络错误不能保证.

##### 副本日志(Quorum,ISR,状态机)

kafka分区是一个副本日志,副本日志在分布式数据系统中是基本的部分,且有许多实现的方式,副本日志可以被其他系统使用,因为状态机是分布式系统主要的容错措施.

副本日志模型模拟了进程达成一致的序列值.有许多的实现方式,但是最简单最快速的方式就是使用一个可以决定提供序列值的leader.只要leader存活,follower仅仅需要拷贝value值和leader选择的顺序信息.

当然如果leader没有失败就不需要follower的存在,当leader没有死亡的时候,需要从follower中选取一个新的leader,但是follower自身会落后或者宕机,所以必须保证follower为最新的状态.日志副本算法的功能保证了必须提供在消息提交且leader失败的情况下,新的leader必须要也含有这些消息.

如果leader等待follower在声明提交之前获取消息,然后就变成了候选的可选leader.

基本的方法就是对提交决定和leader选举进行投票,这个不是kafka做的行为,为了理解这个原理.假定有2*f+1个副本,如果f+1副本的消息优先于leader声明的消息,且从f+1个日志中选举最完整的日志作为新的leader.因为在任意f+1个副本中,必须至少一个副本包含所有提交的消息.这个副本日志是最完整的,因此会被选做新的leader.

有许多关于算法处理的细节.(例如精确定义日志完整方法,保证日志在leader是失败期间一致性的方法或者改变服务器列表的方法).这里不做详述.

这种投票方式的延时依赖于最快的服务器,就是如果副本因子是3,延时取决于最快的follower而不是最慢的follower.在这里涉及到许多Zk的算法,比如ZAB,Raft,以及Viewstamped Replication算法.

这种投票方式的缺陷就是在没有可选择的leader中不能允许大量的失败.3个数据副本中可以容错1个,容错2台需要5个副本.在经验中,对于一个实验的系统中仅仅可以容错1个失败,但是每写5次,会使用5x的磁盘需求和1/5的吞吐量.对于大数据量是存在问题的.这就是为什么quorum算法需要在集群中配置的原因.

kafka使用不同的方法区选择quorum集合.kafka没有使用投票措施,而是动态的维护同步副本(ISR).这个同步副本需要跟随leader.这个集合的成员对于leader来说都是合格的.

写出到kafka分区也会被考虑到在ISR中写入.对于kafka使用模型来说是很重要的.使用ISR模型和f+1个副本,kafka topic可以实现f个容错,且不会丢失提交的消息.

无论是多数一致的投票方式还是ISR的方式都会在提交消息之前获取同样数量副本的同意.不使用最慢速的服务器提交消息时多数一致的投票方式的优势.但是通过允许客户端选择是否阻塞消息的提交进行改善,且由于需要少量的副本因子需要额外的吞吐量和磁盘空间.

使用数据对宕机节点进行恢复对于kafka来说是不必要的.对于副本算法来说并不是通用的处理方式.这种方式有两个重要的方式,首先,磁盘错误是通用的问题,其次,每次写入的时候不希望使用同步措施用于进行一致性保证.这样会降低系统性能.

使用副本是ISR策略保证了在重新进入之前,即使是在宕机的过程中有未刷写的丢失数据都会完全的重新同步.

##### 未清除的leader选举，所有副本都失败的处理

kafka需要保证数据的丢失问题可以保证至少有一个副本保持同步,否则如果所有副本全部死亡,这个断言就不成立了.然而在所有副本死亡的时候,实验系统需要进行一些操作.如果确实发生了这样的情况,需要考虑到发生的情况.有两种可以实现的方式.

1. 等待ISR副本返回文件中，并且选择这个副本作为leader
2. 选择首个复活的副本作为leader

这个是数据一致性和可得性的交换，如果等待ISR中的副本，那么只要副本宕机就不可以获取。如果副本给销毁或者数据丢失，那么就会永久性的宕机。另一方面，非同步副本回到文件并变成leader，那么日志会变成信任源，尽管不能保证提交每条消息。默认情况下，kafka选择首个且支持一致性副本的等待，这个行为会被使用参数`unclean.leader.election.enable`改变。

##### 可用性和持久性保证

当写入kafka的时候，生产者可以选择是否等待消息被识别。注意被所有的副本识别不保证指定的副本集合会接收到消息。默认情况下，当ack为all的1时候，只要当前同步副本接受到消息识别就会发送。例如，如果topic配置仅仅2个副本，且一个副本失败了，指定ack=all的写操作会执行成功，但是如果现存的副本也失败了写出也会丢失。

尽管这个保证了分区的最大可用性，但是在某些情况下达不到期望的效果。因此，提供两种topic等级的配置，这些配置可以用于选择消息。

1.  关闭未清理的leader选举

   如果所有副本都不可用，且分区再之前leader可用之前也不可使用。这个就保证了不会存在消息丢失的可能性。

2. 指定一个最小的ISR大小，当ISR大于一个最小的数的时候，分区仅仅会接受写操作，这样是防止刚刚写入的消息的丢失。这个设置仅仅在生产者设置了ack=all的时候生效，且保证消息会被至少一个同步副本识别。这个是提供了数据一致性和可用性间的权衡措施。如果最小ISR值越大，就能保证更好的数据一致性。因为消息保证可以写出更多的副本，这样就可以降低数据丢失的可能性。但是会降低可用性，因为分区再写操作的时候是不可以使用的。

##### 副本管理

上述关于副本日志的讨论覆盖了仅仅单个日志。但是kafka集群会管理成千上万个这样的分区。期望去使用Round-Robin的方式去对分区进行再次平衡的操作。用于避免在少数节点上聚集着大量分区的情况。同样的，尝试去平衡leader关系，以便于每个节点按比例的都是一些分区的leader。

同时优化leadership选举也很重要，因为这是可用性的重要窗口。leader选举的本地实现在每个分区上运行选举。

这里需要选取一个broker作为controller。这个控制器会在broker层级上发现失败，且用于改变在失败broker中所有受到影响的leader。结果就是可以对leader关系改变情况进行批量获取，这样会使得选举过程开销更小且对于大量分区速度也会更快。如果控制器失败了，一个存活的broker会变成新的控制器。

#### 日志合并

日志合并保证了kafka总是保留每条消息key的最新value值。在系统失败或者应用死亡的时候会使用脚本恢复状态。或者是在应用重启之后重载缓存。

至今为止我们藐视了仅仅数据存留的简单使用，这里旧的数据在指定周期的时间之后或者是日志到达指定的大小之后会被抛弃。对于临时的事件日志相当有效。但是数据流的重要的类是一个使用key可变的数据结构。

下面来讨论数据流的离散示例，假设topic包含用户邮件地址，每次用户更新地址的时候，会发送一个消息到topic中（key是用户ID）。假定发送下述消息的时间周期是123，每条消息做出的改变如下：

```shell
123 => bill@microsoft.com
        .
        .
        .
123 => bill@gatesfoundation.org
        .
        .
        .
123 => bill@gmail.com
```

日志合并给出了一种粒度更细的留存策略,以便于可以保证留存至少上次更新的值.下面是日志合并的使用时机:

1. 数据库改变:

   经常在多个数据系统中有一个数据集合,且这些系统中存在某个类型的数据库.例如,可以存在一个数据库,一个缓存,一个搜索引擎,和一个hadoop集群.数据库的变化需要反映到缓存,搜索引擎以及hadoop上.如果处理实时更新的时候,需要最新的日志.但是如果需要重载缓存或者是失败恢复的时候则需要全量的数据集.

2. 事件源: 

   可以使用应用设计定位查询进程的设计方式,使用日志的变化作为应用的主要存储

3. 高可用

   进程可以进行本地计算,这个就是可以使用日志变化进行容错,这样对本地状态有效.这样其他1进程可以重载这些变化且失败的时候可以继续.

在这些情况下,需要处理实时变化,但是,当机器宕机或者数据需要重载的时候,亦或者是重新处理的时候,需要进行全量加载.日志合并需要满足后备topic的存在.

主要思路十分简单,**如果有无限日志存在,且记录了上述的所有编号,可以在每次开始的时候捕捉系统的变化.使用完整日志,可以通过重演前N条记录,从而恢复到任何一点处.**

假想的完整日志对于实际系统来说不实际,简单日志存留原理会抛出许多之前的更新情况,这样就不能恢复当前的状态了.现在从日志首部恢复不会再重新创建当前状态,因为旧的更新不能够被捕捉到.

日志合并是细粒度的记录存留策略。而不是粗粒度的时基存留策略。这个相关可选性的移除了最近的同key记录，这种方式保证了获取至少一个key的最近状态。

留存策略可以在每个topic上设置，因此单个集群可以有一些按照时间或者日志大小设置的留存策略，其他的留存策略就是按照合并方式处理的。

##### 日志合并基础

下面是kafka日志逻辑数据结构的图

<img src="E:\截图文件\Log.png" style="zoom:67%;" />

日志头部是kafka日志的传统标识符，使用紧缩式的序列偏移量，且存留了所有的消息。日志合并添加了处理日志尾部的策略。上图显示了携带有日志尾部指针的日志结构。注意日志尾部消息在首次写入的时候，存留了原始的偏移量，这个值是不变的。

同时所有的偏移量保持可以的位置指针，即便是消息被合并了也是如此。这种情况下位置指针不能分别下一个出现在日志中的最高位offset。例如，图中36,37,38是等价的位置，根据上面的原理这里应该返回38这个值。

日志合并也可以进行删除，如果一个消息使用一个key同时使用null作为value值，这时候日志合并就相当于删除的操作。这个删除标志位会导致之前的value值，但是删除标志位特别地就是在指定的周期过后，删除标记位会从日志范围内移出。删除操作不存在的时间点称作**删除存留点**。

合并操作周期性的在后台进行运作。清理的过程中不会阻塞读取，且可以限制到指定的IO数量。避免影响生产者和消费者的运行。日志合并的实际情况类似下图：

<img src="E:\截图文件\日志合并.png" style="zoom:67%;" />

##### 日志合并功能

日志合并确保了下述特性

1. 任何在日志头部的消费者可以获取到写入的所有消息，这些消息使用序列偏移量。使用参数`min.compaction.lag.ms`保证合并前写出后最小时间.参数`max.compaction.lag.ms`保证了最大值.
2. 消息的顺序时得到保证的,合并不会对消息进行重排序,仅仅会移除一些数据而已
3. 消息的偏移量不会改变,偏移量是日志中的唯一永久标识符
4. 任何从日志尾部开始运行的消费者可以找到所有记录中最后一个状态位.此外,可以看到所有删除记录的删除标记位.

##### 日志合并细节

日志合并有日志清理器处理,后台线程池会重新复制日志段文件,引出出现在日志头的记录.每个合并线程按照如下方式工作:

1. 选择日志头到日志为比例最重的日志
2. 创建日志每个key的上一个offset的简洁的描述
3. 从头到尾重新拷贝日志,并移除日志中最新出现的key.
4. 日志头的信息基本上是受到空间影响的hash表,每个条目使用仅仅24字节,使用8GB的清理器缓冲区,一个清理器可以清除大约366GB的日志头.

##### 配置日志清理器

日志清理器默认开启,会启动清理器线程池,添加指定日志的属性用于启动指定topic的日志清理:

```
`log.cleanup.policy=compact`
```

`log.cleanup.policy`是broker的属性,定义在broker的服务器属性中`server.properties`.这个参数会影响集群中虽有未配置相关参数的topic。日志清理器保留头部未合并的最小数量，可以使用下述参数开启：

```
`log.cleaner.min.compaction.lag.ms`
```

这样可以阻止新的消息被合并.如果没有设置，所有日志片段除了最后一个其他都可以用于合并。激活的文件段不会被合并，除非所有消息都比合并的最小之间要老。日志清理器可以配置，用于保证合并的最大延时。

```
`log.cleaner.max.compaction.lag.ms`
```

