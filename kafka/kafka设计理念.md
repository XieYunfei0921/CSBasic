#### 持久化

kafka依赖于文件系统去存储和缓存消息.但是通识上来说磁盘读写缓慢的.为了弥补性能上的差异,现代OS在主存中进行磁盘缓存(**高速缓存**).现代OS会分配空闲内存空间给磁盘缓存.所有磁盘的读写都会通过主存进行.这个功能不能直接由关闭IO完成,所以尽管处理过程维护了处理中的数据缓存,这些数据会在OS的页缓存中备份,可以高效地存储两次.

进一步,来说,可以在JVM的基础上进行构建,使用java内存是需要注意到两点

1. 对象存储在内存中开销非常大,经常是数据存储的两倍
2. 随着堆内数据的增加,GC变得更加的缓慢

因此,需要同时使用文件系统和依赖页缓存.如果服务重启缓存保持运行.

消息系统中使用的持久化的数据结构,经常每个消费都会使用一个B树或者生成其他随机数去维护消息的元数据.B树是最通用的数据结构,可以获取消息系统中大量的事务/非事务语义.查找的时间复杂度为O(log N).正常情况下基本上等于是个常数时间,但是对于磁盘操作来说并不是这样.磁盘查找需要10ms,且每个磁盘同一时刻只允许一次查找,所以并行度被限制.假定磁盘查找需要大量的开销.因此存储系统混合了高速缓存和慢速的磁盘查找.

持久化的队列可以被简单的读取并添加到文件中.这个数据结构认为所有的操作都是O(1)的时间复杂度,且读取不会阻塞写出和其他操作.尽管如此,查找的性能仍然很大,这样在大量的读写情况下,使用1/3的代价和3倍的容量.

为了获取虚拟磁盘空间,提供一些消息系统中不常使用的功能.例如,kafka中数据不是消费完毕就会删除的,而是需要保持一定的周期,这个会对消费者提供很大的处理灵活性.

#### 高效

主要通过处理web的激活的数据,这个数据的量比较大,每个分页都会产生大量的写出操作,此外,假定每条消息都被至少一个消费者.

注意影响系统效率的主要行为许多小的IO操作,以及过多的字节拷贝工作.

小IO问题发生在客户端和服务器之间且用于服务器自己的持久化操作.为了避免这种情况，协议中围绕着**消息集合**进行抽象。

这个会自然的将消息聚合在一起，允许网络将组消息聚合在一起且分担网络开销，而不是同一个时间仅仅发送一条消息。在服务器运行的时候，服务器会轮流地添加消息块到日志中，消费者会获取一个数据块的消息。

这个简单的优化会加速生成的幅度。批量获取会生成更大的网络数据包以及较大的磁盘操作以及连续的数据块。kafka可以将其转换为随机的消息写入到消费者的工作流中。

另一个低效的操作就是字节拷贝了，关键的问题是加载数据的时候影响较大。为了避免这种情况下，使用标准的二进制消息格式，这个可以被生产者，broker，消费者共享。因此数据块的传输可以不修改的进行。由broker维护的消息日志仅仅是一个文件目录，消息集序列会被写入到磁盘中，生产者和消费者的消息形式相同。

理解发送文件的影响，重点是理解通用数据意义：

1. 操作系统读取磁盘数据到内核的页缓存中
2. 应用从内核空间读取数据到用户缓冲区中
3. 应用将数据写回内核中
4. 操作系统复制socker缓冲区的数据到一个NIC缓冲区中，这里可以通过网络发送数据

这个是低效的，有4次拷贝以及两个系统调用。使用发送文件的方式，通过使用OS发送页缓存的数据到网络中，重新拷贝被避免了。所以在这个优化路径中，仅仅最后需要拷贝到NIC缓冲区中。

希望对多个消费者进行通用的操作。使用**零拷贝**的优化技术，数据仅仅会拷贝到页缓存中一次，且在每次消费的时候会重新使用（而不是存储在内存中，每次需要拷贝到用户空间中）。这个允许消息按照一定的比率进行消费。

页缓存和发送文件的联合使用意味着kafka集群中可以在磁盘上没有读取的操作，因为可以通过缓存的范式进行数据服务。

#### 端对端的批次压缩

在一些情况下，性能瓶颈不是CPU或者磁盘而是网络的带宽。这个对于pipeline来说，需要通过广域网的数据中心发生数据。当然，用于可以将消息压缩，但是压缩比率可能很低。高效的压缩需要压缩多个消息而不是单条的进行压缩。kafka支持高效的批格式处理，一批消息可以一起压缩且按照这个格式发送到服务器。批次的消息会被写入，且在日志中保留着压缩的形式，且只有消费者可以对其进行解压缩。

kafka支持Gzip，Snappy，lz4，zStandard压缩协议。

#### 生产者

##### 负载均衡

生产者直接将消息发送到broker中，这个broker是分区的leader，且没有任何的中间路由层。为了帮助生产者进行这个操作，kafka节点可以回应元数据关于服务器存活状态以及leader的位置信息的请求。客户端控制发布消息的分区信息，这个可以随机处理，由随机的负载均衡处理，可以被分区函数的语义处理。这里保留分区语义的接口，允许用于指定分区的key，且使用hash进行分区。这个可以允许消费者去进行消费的位置假设。分区的方式可以显示地允许消费者的位置感知处理。

##### 异步发送

批量处理具有高效的特性，为了开启kafka的批量处理，生产者需要在内存中累加数据，且需要在单次请求中发送大批量数据。这个批次可以设置为指定数量的消息，或者是等待指定时间范围的消息(例如 64K或者 10ms)。这样会降低服务器的IO操作次数，配置缓存且获取更高的吞吐量。

#### 消费者

##### 推送和拉取数据的比较

首先需要考虑的就是消费者是否需要从broker拉取数据，还是broker将数据推送给消费者。kafka使用了传统的处理方案，这个方案使用了共享的消息系统，数据从生产者推送到broker，且由消费者从broker中拉取。

一些以日志为中心的系统，例如Scribe和Flume，数据推送的方式是推送式的。但是基于推送式的系统处理不同消费者的时候就有问题。这里对于大多数消费者可以消费者最大的比率，在推送式系统中意味着消费者会被压垮（消费比率不足的时候）。

基于拉取的另一个优势就是可以将批量数据发送给消费者。基于推送的系统必须要选择是立即发送请求还是累积更多的数据再发送。基于拉取的系统的消费者总是在当前日志指针之后拉取可用的消息，所以消费者可以没有延时的获取批量

##### 消费者位置指针

消费者的位置指针指示了消费的位置，这个是消息系统的关键性能。大多数消息系统保持broker中消费的元数据。随着消息被消费者消费，broker会记录事实位置或者等待消费者的确认。由于大多说消息系统的存储数据结构扩容能力很长，因此当broker知道消息被消费之后消息会被立即删除，保持数据量的大小。

如果broekr每次处理消费的记录的时候记录消息，如果消费者处理消息失败那么消息就会丢失。为了解决这个问题，许多消息系统设置了将消息标志为发送但为消费的标记。这样broker就会等待消费者确认消费的状态。这个策略修正了消息丢失的问题，但是会引入新的问题。首先，如果消费者处理消息，但是在发送确认信息前失败了，那么消息就会被消费两次。关于这个问题，现在broker必须保证每条信息的多个状态参数(首次使用的时候会加锁,这样就不能第二次使用,然后将其进行临时标记,以便可以可以移除).

kafka进行了不同的处理,topic被划分成有序的分区,每个分区被每个消费者组的指定的消费者消费.这就意味着每个分区的消费者位置是一个整数,是下一条消费消息的偏移量.这个使得消费状态非常简单,就是分区的一个数字.这个状态可以周期性设置检查点.消费者可以倒回到旧的偏移量并重新消费数据.

##### 离线数据负载

可扩展的持久化引擎允许消费者周期性的消费离线系统数据(例如Hadoop或者是相关数据仓库的数据)在hadoop的情况下,通过在map任务分割负载对其进行并行化处理,hadoop系统使用任务管理器,任务失败则会进行安全的重启.

##### 静态关系

静态关系用于提升流式应用的可用性,消费者组合其他应用按照组的平衡协议的基础上.重平衡协议依赖于组协调者去分配实例的id给组员.产生的id是临时的,且在重启或者重新加入的时候会改变.对于基于应用的消费者来说,动态关系可能引起较大规模的任务重分配.对于较大的状态应用中,shuffle任务需要长时间去恢复本地状态.kafka组管理协议允许组成员提供持久化的实例id.基于这些id信息,组关系可以保持不变

如果希望使用静态关系:

- broker和客户端都要升级到2.3版本以上
- 设置`ConsumerConfig#GROUP_INSTANCE_ID_CONFIG`对于每个消费者实例是组内唯一标识的.
- 对于kafka流式应用,对于kafka流式对象使用`ConsumerConfig#GROUP_INSTANCE_ID_CONFIG` 作为唯一标识.

#### 消息传输语义

#### 副本

##### 副本日志(Quorum,ISR,状态机)

##### 未清除的leader选举

##### 可用性和持久性保证

##### 副本管理

#### 日志合并

##### 日志合并基础

##### 日志合并功能

##### 日志合并细节

##### 配置日志清理器

